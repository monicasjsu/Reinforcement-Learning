{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgNVP1HBKrgESPVU1Xo/ez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/Reinforcement-Learning/blob/master/DL_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOkOmqZSNe9Q"
      },
      "source": [
        "Use the convnet example provided on Canvas as a starting point and add the following two features:\n",
        "1. Add He initialization and compare the training results with the base model.\n",
        "2. Add Nadam optimization and compare the training results with the base model.\n",
        "3. Combine the two modification and explain the overall impact of these two enhancements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQZa1RhlOjtb"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SszVe4arINeR",
        "outputId": "97b7bb36-239d-44dd-e118-82e9733b787b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install qhoptim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: qhoptim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QYllPMFIvsy",
        "outputId": "55b32400-a229-4e68-d650-ca476961919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "pip install pywick"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pywick in /usr/local/lib/python3.6/dist-packages (0.5.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from pywick) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pywick) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pywick) (1.6.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pywick) (1.15.0)\n",
            "Requirement already satisfied: hickle in /usr/local/lib/python3.6/dist-packages (from pywick) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pywick) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pywick) (1.1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from pywick) (7.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pywick) (0.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pywick) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from hickle->pywick) (0.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pywick) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywick) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps-XR9DPITXp"
      },
      "source": [
        "# from torch.optim.optimizer import Optimizer\n",
        "from qhoptim.pyt import QHM, QHAdam\n",
        "import qhoptim\n",
        "import pywick"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnQ5IRw-O9Db"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l48H1VqkPCPt"
      },
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBtx767LPIz0"
      },
      "source": [
        "#Getting MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQVNetiBPMl0"
      },
      "source": [
        "#Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRupGlonPPG1"
      },
      "source": [
        "#Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        #He Initialization\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8CFF0rHPhBA"
      },
      "source": [
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZarHNv8dPmle"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Nadam Optimiser\n",
        "optimizer = qhoptim.pyt.QHAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999), nus=(1.0, 1.0), weight_decay=0.0, decouple_weight_decay=False, eps=1e-08)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRcu04PBPqkT",
        "outputId": "f563ea30-faad-4554-e7f9-fc480513bd0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/qhoptim/pyt/qhadam.py:133: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1_adj).add_(1.0 - beta1_adj, d_p)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.1710\n",
            "Epoch [1/5], Step [200/600], Loss: 0.0791\n",
            "Epoch [1/5], Step [300/600], Loss: 0.1371\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0697\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0713\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0829\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0524\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0453\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0481\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0206\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0197\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0913\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0860\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0355\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0245\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0507\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0088\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0757\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0314\n",
            "Epoch [4/5], Step [200/600], Loss: 0.1525\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0499\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0184\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0309\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0092\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0288\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0605\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0082\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0211\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0510\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBdQE6dOPtuk",
        "outputId": "e7bf7061-36d8-43cc-d7bc-35ecd4d300af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 98.79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_6a9DjOPwv5"
      },
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIt2fnsOY-av"
      },
      "source": [
        "**Conclusion:** \n",
        "\n",
        "\n",
        "*   **Got an accuracy of 99.12 for the base model**\n",
        "*   **Added He initialization and got an accuracy of 99.0%**\n",
        "*   **Added Nadam initilization and got an accuracy of 98.94%**\n",
        "*   **Combining both He and Nadam initilization got an accuracy of 98.79%**\n",
        "\n"
      ]
    }
  ]
}