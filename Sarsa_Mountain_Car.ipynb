{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarsa_Mountain_Car.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7E0BSb25eehwN+RShyEPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicasjsu/Reinforcement-Learning/blob/master/Sarsa_Mountain_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HAAIfDk9DMM"
      },
      "source": [
        "**Import the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaucP61X4sDj",
        "outputId": "2ddee67d-78f1-424e-aceb-950002cf6245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!apt-get install python-opengl -y\n",
        "\n",
        "!apt install xvfb -y\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "!pip install piglet\n",
        "\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 2s (246 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144617 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.6 [783 kB]\n",
            "Fetched 783 kB in 2s (376 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146972 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n",
            "Collecting piglet\n",
            "  Downloading https://files.pythonhosted.org/packages/11/56/6840e5f45626dc7eb7cd5dff57d11880b3113723b3b7b1fb1fa537855b75/piglet-1.0.0-py2.py3-none-any.whl\n",
            "Collecting piglet-templates\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/dc/d628dcdf0b38b8f230e9c2309bfa370d2e3fb95e9e9c260213d10fde91ac/piglet_templates-1.0.0-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (20.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Collecting Parsley\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (0.35.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Installing collected packages: Parsley, piglet-templates, piglet\n",
            "Successfully installed Parsley-1.3 piglet-1.0.0 piglet-templates-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIkBZ00i9M2I"
      },
      "source": [
        "**Create the Gym environment**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ_uAnFF5Y1K"
      },
      "source": [
        "env_name = 'MountainCar-v0'\n",
        "env = gym.make(env_name)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxQwkO3N5dit",
        "outputId": "3534e1db-bf67-4af8-e05f-063220cfa908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Action Set size :\", env.action_space)\n",
        "print(\"Observation set shape :\", env.observation_space)\n",
        "print(\"Highest state feature value :\", env.observation_space.high)\n",
        "print(\"Lowest state feature value:\", env.observation_space.low)\n",
        "print(env.observation_space.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Set size : Discrete(3)\n",
            "Observation set shape : Box(2,)\n",
            "Highest state feature value : [0.6  0.07]\n",
            "Lowest state feature value: [-1.2  -0.07]\n",
            "(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41xhAVu89T37"
      },
      "source": [
        "**Set the hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnhU08cI5hh4"
      },
      "source": [
        "n_states = 40  # number of states\n",
        "episodes = 10  # number of episodes\n",
        "\n",
        "initial_lr = 1.0  # initial learning rate\n",
        "min_lr = 0.005  # minimum learning rate\n",
        "gamma = 0.99  # discount factor\n",
        "max_steps = 300\n",
        "epsilon = 0.05"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI2E6ULo5jXZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "env = env.unwrapped\n",
        "env.seed(0)  \n",
        "np.random.seed(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8I9iuyw9hc5"
      },
      "source": [
        "**Define a function for discretization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hipVDZkl5l9A"
      },
      "source": [
        "def discretization(env, obs):\n",
        "    env_low = env.observation_space.low\n",
        "    env_high = env.observation_space.high\n",
        "\n",
        "    env_den = (env_high - env_low) / n_states\n",
        "    pos_den = env_den[0]\n",
        "    vel_den = env_den[1]\n",
        "\n",
        "    pos_high = env_high[0]\n",
        "    pos_low = env_low[0]\n",
        "    vel_high = env_high[1]\n",
        "    vel_low = env_low[1]\n",
        "\n",
        "    pos_scaled = int((obs[0] - pos_low) / pos_den) \n",
        "    vel_scaled = int((obs[1] - vel_low) / vel_den)  \n",
        "\n",
        "    return pos_scaled, vel_scaled"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RSea3Ew52bt",
        "outputId": "6f0d941b-a7a2-4cb4-d873-78bf7bd00bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "q_table = np.zeros((n_states,n_states,env.action_space.n))\n",
        "total_steps = 0\n",
        "for episode in range(episodes):\n",
        "   obs = env.reset()\n",
        "   total_reward = 0\n",
        "   # decreasing learning rate alpha over time\n",
        "   alpha = max(min_lr,initial_lr*(gamma**(episode//100)))\n",
        "   steps = 0\n",
        "\n",
        "   #action for the initial state using epsilon greedy\n",
        "   if np.random.uniform(low=0,high=1) < epsilon:\n",
        "        a = np.random.choice(env.action_space.n)\n",
        "   else:\n",
        "        pos,vel = discretization(env,obs)\n",
        "        a = np.argmax(q_table[pos][vel])\n",
        "  \n",
        "   while True:\n",
        "      env.render()\n",
        "      pos,vel = discretization(env,obs)\n",
        "    \n",
        "      obs,reward,terminate,_ = env.step(a) \n",
        "      total_reward += abs(obs[0]+0.5) \n",
        "      pos_,vel_ = discretization(env,obs)\n",
        "\n",
        "      #action for the next state using epsilon greedy\n",
        "      if np.random.uniform(low=0,high=1) < epsilon:\n",
        "          a_ = np.random.choice(env.action_space.n)\n",
        "      else:\n",
        "          a_ = np.argmax(q_table[pos_][vel_])\n",
        "\n",
        "      #q-table update\n",
        "      q_table[pos][vel][a] = (1-alpha)*q_table[pos][vel][a] + alpha*(reward+gamma*q_table[pos_][vel_][a_])\n",
        "      steps+=1\n",
        "      if terminate:\n",
        "          break\n",
        "      a = a_\n",
        "   print(\"Episode {} completed with total reward {} in {} steps\".format(episode+1,total_reward,steps)) \n",
        "while True: #to hold the render at the last step when Car passes the flag\n",
        "   env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 1 completed with total reward 10681.592878022653 in 32927 steps\n",
            "Episode 2 completed with total reward 787.9200319408282 in 2908 steps\n",
            "Episode 3 completed with total reward 1726.4446335156654 in 5812 steps\n",
            "Episode 4 completed with total reward 1093.8120666928066 in 3982 steps\n",
            "Episode 5 completed with total reward 2037.6759841203943 in 5999 steps\n",
            "Episode 6 completed with total reward 740.6977100558029 in 2894 steps\n",
            "Episode 7 completed with total reward 860.4562672146648 in 3157 steps\n",
            "Episode 8 completed with total reward 581.5362914429438 in 2693 steps\n",
            "Episode 9 completed with total reward 3582.4670596187384 in 8886 steps\n",
            "Episode 10 completed with total reward 1531.109979650578 in 5667 steps\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}